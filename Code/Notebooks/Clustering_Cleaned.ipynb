{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0eed795",
   "metadata": {},
   "source": [
    "# Ticket Clustering — TF-IDF & Embedding-Based\n",
    "\n",
    "This notebook explores clustering of support tickets using two unsupervised algorithms on two types of vector representations.\n",
    "\n",
    "### Techniques:\n",
    "- **K-Means Clustering**\n",
    "- **Agglomerative Clustering** (Ward linkage)\n",
    "\n",
    "### Representations:\n",
    "- **TF-IDF Vectors**\n",
    "- **Sentence Embeddings** (`MiniLM` from Sentence Transformers)\n",
    "\n",
    "Each method is evaluated on how well the resulting clusters align with the true ticket categories  \n",
    "(optional, if labels are available). To enable comparison, we use the Hungarian algorithm to optimally match predicted cluster labels to ground-truth classes before computing metrics like accuracy and F1-score.\n",
    "\n",
    "All text is filtered for private information before clustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba99384",
   "metadata": {},
   "source": [
    "## Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages:\n",
    "# pip install pandas numpy matplotlib seaborn scikit-learn umap-learn sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === General Purpose ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "# === Clustering + Evaluation ===\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, silhouette_samples,\n",
    "    silhouette_score, calinski_harabasz_score, davies_bouldin_score,\n",
    "    adjusted_rand_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scipy.optimize import linear_sum_assignment  # Hungarian Algorithm\n",
    "\n",
    "# === Vectorization + Reduction ===\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import umap.umap_ as umap\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dcbce3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Config ===\n",
    "EMBEDDING_METHOD = \"sentence-transformer\"                  # Options: \"tfidf\", \"sentence-transformer\"  \n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"        # Used only if method is \"sentence-transformer\"\n",
    "N_CLUSTERS = 7                              # Set to number of expected groups (e.g., issue types)\n",
    "VISUALIZE_WITH = \"umap\"                     # Options: \"pca\", \"umap\"   \n",
    "DATA_PATH = \"cleaned.csv\"                   # Path to your preprocessed dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88cb48",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c64a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Dataset ===\n",
    "# Make sure your CSV uses ; as separator if needed\n",
    "df = pd.read_csv(\"Autotask_KB_Stemmed.csv\", sep=';')\n",
    "texts = df[\"combined_text\"].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8a6dd",
   "metadata": {},
   "source": [
    "### Chose embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7090401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Embedding Step ===\n",
    "# Toggle between TF-IDF or SentenceTransformer\n",
    "\n",
    "if EMBEDDING_METHOD == \"tfidf\":\n",
    "    print(\"Embedding with TF-IDF\")\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    X_dense = X.toarray()  # Required for UMAP and silhouette scoring\n",
    "else:\n",
    "    print(f\"Embedding with SentenceTransformer: {EMBEDDING_MODEL}\")\n",
    "    model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "    X = model.encode(texts, show_progress_bar=True)\n",
    "    X_dense = X  # Already dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d476e03",
   "metadata": {},
   "source": [
    "## KMeans Clustering\n",
    "This section applies the KMeans algorithm to the embedded ticket data.\n",
    "\n",
    "- Requires dense input (TF-IDF or sentence embeddings)\n",
    "\n",
    "It helps reveal:\n",
    "- Natural groupings of tickets based on content\n",
    "- Cluster assignments for exploratory analysis or labeling\n",
    "\n",
    "Note: KMeans assumes clusters are spherical and of similar size (Euclidean space).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c638f2b3",
   "metadata": {},
   "source": [
    "### K-Means Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === KMeans Clustering ===\n",
    "kmeans = KMeans(\n",
    "    n_clusters=N_CLUSTERS,    # Number of clusters to create\n",
    "    init='k-means++',         # Smart centroid initialization\n",
    "    n_init='auto',            # Scikit-learn ≥1.2 auto-detects optimal n_init\n",
    "    max_iter=300,             # Maximum number of iterations\n",
    "    algorithm='lloyd',        # Standard KMeans algorithm\n",
    "    random_state=42           # For reproducibility\n",
    ")\n",
    "\n",
    "clusters = kmeans.fit_predict(X_dense)\n",
    "df[\"cluster\"] = clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b101660",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a312c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === KMeans Clustering ===\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_dense)\n",
    "df[\"cluster\"] = clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8ea51",
   "metadata": {},
   "source": [
    "### Optional: Evaluation with True Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Issue Type\" in df.columns:\n",
    "    true_labels = df[\"Issue Type\"]\n",
    "    ari = adjusted_rand_score(true_labels, clusters)\n",
    "    sil_score = silhouette_score(X_dense, clusters)\n",
    "\n",
    "    def cluster_purity(y_true, y_pred):\n",
    "        contingency = contingency_matrix(y_true, y_pred)\n",
    "        return np.sum(np.amax(contingency, axis=0)) / np.sum(contingency)\n",
    "\n",
    "    purity = cluster_purity(true_labels, clusters)\n",
    "\n",
    "    contingency = contingency_matrix(true_labels, clusters)\n",
    "    row_ind, col_ind = linear_sum_assignment(-contingency)\n",
    "    cluster_to_label_map = dict(zip(col_ind, row_ind))\n",
    "\n",
    "    mapped_preds = [cluster_to_label_map[c] for c in clusters]\n",
    "    mapped_preds = np.array(mapped_preds)\n",
    "    y_true_mapped = np.array(true_labels.map({label: i for i, label in enumerate(sorted(df[\"Issue Type\"].unique()))}))\n",
    "\n",
    "    print(\"\\n=== KMeans Clustering Evaluation Metrics ===\")\n",
    "    print(f\"Adjusted Rand Index (ARI): {ari:.4f}\")\n",
    "    print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "    print(f\"Cluster Purity: {purity:.4f}\")\n",
    "\n",
    "    print(\"\\n=== Metrics After Hungarian Mapping ===\")\n",
    "    print(classification_report(y_true_mapped, mapped_preds, target_names=sorted(df[\"Issue Type\"].unique())))\n",
    "\n",
    "    cm = confusion_matrix(y_true_mapped, mapped_preds)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "    plt.title(\"Confusion Matrix (Aligned Clusters vs True Labels)\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74132c8c",
   "metadata": {},
   "source": [
    "### Cluster Sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7401d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = df[\"cluster\"].value_counts().sort_index()\n",
    "cluster_table = pd.DataFrame({'Cluster': cluster_counts.index, 'Number of Items': cluster_counts.values})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(cluster_table['Cluster'], cluster_table['Number of Items'], color='skyblue')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Items')\n",
    "plt.title('Number of Items per Cluster')\n",
    "plt.xticks(cluster_table['Cluster'])\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5147ff",
   "metadata": {},
   "source": [
    "### Cluster Visualization (PCA or UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_WITH == \"pca\":\n",
    "    reducer = PCA(n_components=2)\n",
    "elif VISUALIZE_WITH == \"umap\":\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "else:\n",
    "    raise ValueError(\"Invalid VISUALIZE_WITH setting\")\n",
    "\n",
    "X_2d = reducer.fit_transform(X_dense)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_2d[:, 0], X_2d[:, 1], c=clusters, cmap='viridis', s=30)\n",
    "plt.title(\"KMeans Clustering of Ticket Texts\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9df461",
   "metadata": {},
   "source": [
    "\n",
    "### Intrinsic Clustering Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_intrinsic_metrics(X, labels, title=\"Clustering Quality Metrics\"):\n",
    "    sil = silhouette_score(X, labels)\n",
    "    ch = calinski_harabasz_score(X, labels)\n",
    "    db = davies_bouldin_score(X, labels)\n",
    "\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"Silhouette Score: {sil:.4f} (higher = better)\")\n",
    "    print(f\"Calinski-Harabasz Index: {ch:.4f} (higher = better)\")\n",
    "    print(f\"Davies-Bouldin Index: {db:.4f} (lower = better)\")\n",
    "\n",
    "evaluate_intrinsic_metrics(X_dense, clusters, \"KMeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98e760",
   "metadata": {},
   "source": [
    "### Cluster Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordclouds(X_text, clusters):\n",
    "    texts_by_cluster = defaultdict(str)\n",
    "    for i, c in enumerate(clusters):\n",
    "        texts_by_cluster[c] += \" \" + X_text.iloc[i]\n",
    "\n",
    "    for c in range(N_CLUSTERS):\n",
    "        wc = WordCloud(width=600, height=400, background_color='white').generate(texts_by_cluster[c])\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Word Cloud - Cluster {c}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_wordclouds(df[\"combined_text\"], clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629986d",
   "metadata": {},
   "source": [
    "### Silhouette Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c875db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette(X, labels, title=\"Silhouette Plot\"):\n",
    "    silhouette_vals = silhouette_samples(X, labels)\n",
    "    y_lower = 10\n",
    "    for i in range(N_CLUSTERS):\n",
    "        ith_vals = silhouette_vals[labels == i]\n",
    "        ith_vals.sort()\n",
    "        size_i = ith_vals.shape[0]\n",
    "        y_upper = y_lower + size_i\n",
    "        color = plt.cm.nipy_spectral(float(i) / N_CLUSTERS)\n",
    "        plt.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_vals, facecolor=color, edgecolor=color)\n",
    "        plt.text(-0.05, y_lower + 0.5 * size_i, str(i))\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    plt.axvline(x=silhouette_vals.mean(), color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Silhouette Coefficient Values\")\n",
    "    plt.ylabel(\"Cluster\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_silhouette(X_dense, clusters, \"Silhouette - KMeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800cc7c",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering  \n",
    "This section applies Agglomerative Clustering to the embedded ticket representations.  \n",
    "We test different linkage strategies to assess how hierarchical clustering groups the data.\n",
    "\n",
    "### Clustering Setup  \n",
    "We use `ward` linkage with Euclidean distance, which tends to form compact, spherical clusters.  \n",
    "Other options like `average` or `complete` linkage can be tested by changing the `linkage` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Agglomerative Clustering...\")\n",
    "\n",
    "agglo = AgglomerativeClustering(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    metric='euclidean',  # Explicit for clarity\n",
    "    linkage='ward'       # Options: 'average', 'complete', 'ward', 'single'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace08c84",
   "metadata": {},
   "source": [
    "### Run Model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_clusters = agglo.fit_predict(X_dense)\n",
    "df[\"agglo_cluster\"] = agglomerative_clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533d625",
   "metadata": {},
   "source": [
    "### Evaluation with Ground Truth Labels  \n",
    "If true labels are available (e.g. \"Issue Type\"), we evaluate cluster alignment using:  \n",
    "- Adjusted Rand Index (ARI)  \n",
    "- Silhouette Score  \n",
    "- Cluster Purity  \n",
    "We also apply the Hungarian algorithm to remap clusters for label-based metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c889be0",
   "metadata": {},
   "source": [
    "### Confusion Martix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a24f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Issue Type\" in df.columns: \n",
    "    true_labels = df[\"Issue Type\"] \n",
    "    ari_agglo = adjusted_rand_score(true_labels, agglomerative_clusters) \n",
    "    sil_agglo = silhouette_score(X_dense, agglomerative_clusters)\n",
    "\n",
    "    def cluster_purity(y_true, y_pred):\n",
    "        contingency = contingency_matrix(y_true, y_pred)\n",
    "        return np.sum(np.amax(contingency, axis=0)) / np.sum(contingency)\n",
    "\n",
    "    purity_agglo = cluster_purity(true_labels, agglomerative_clusters)\n",
    "\n",
    "    print(\"\\n=== Agglomerative Clustering Evaluation Metrics ===\") \n",
    "    print(f\"Adjusted Rand Index (ARI): {ari_agglo:.4f}\") \n",
    "    print(f\"Silhouette Score: {sil_agglo:.4f}\") \n",
    "    print(f\"Cluster Purity: {purity_agglo:.4f}\")\n",
    "\n",
    "    # Hungarian matching\n",
    "    contingency = contingency_matrix(true_labels, agglomerative_clusters)\n",
    "    row_ind, col_ind = linear_sum_assignment(-contingency)\n",
    "    cluster_to_label_map = dict(zip(col_ind, row_ind))\n",
    "\n",
    "    mapped_preds = [cluster_to_label_map[c] for c in agglomerative_clusters]\n",
    "    mapped_preds = np.array(mapped_preds)\n",
    "    y_true_mapped = np.array(true_labels.map({label: i for i, label in enumerate(sorted(df[\"Issue Type\"].unique()))}))\n",
    "\n",
    "    print(\"\\n=== Metrics After Hungarian Mapping ===\")\n",
    "    print(classification_report(y_true_mapped, mapped_preds, target_names=sorted(df[\"Issue Type\"].unique())))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_mapped, mapped_preds)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Purples\")\n",
    "    plt.title(\"Confusion Matrix (Aligned Agglomerative Clusters vs True Labels)\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca332c",
   "metadata": {},
   "source": [
    "### Cluster Distribution  \n",
    "Visualize the number of samples per cluster to detect imbalance or dominance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ed681",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4)) \n",
    "sns.countplot(x=\"agglo_cluster\", data=df, palette=\"mako\") \n",
    "plt.title(\"Number of Samples per Agglomerative Cluster\") \n",
    "plt.xlabel(\"Cluster\") \n",
    "plt.ylabel(\"Count\") \n",
    "plt.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540c73d",
   "metadata": {},
   "source": [
    "### 2D Projection of Agglomerative Clusters  \n",
    "Reduce embeddings to 2D using PCA or UMAP and plot clusters for spatial interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZE_WITH == \"pca\": \n",
    "    reducer = PCA(n_components=2) \n",
    "elif VISUALIZE_WITH == \"umap\": \n",
    "    reducer = umap.UMAP(random_state=42) \n",
    "else: \n",
    "    raise ValueError(\"Invalid VISUALIZE_WITH setting\")\n",
    "\n",
    "agglo_2d = reducer.fit_transform(X_dense) \n",
    "plt.figure(figsize=(8, 6)) \n",
    "plt.scatter(agglo_2d[:, 0], agglo_2d[:, 1], c=agglomerative_clusters, cmap='mako', s=30) \n",
    "plt.title(\"Agglomerative Clustering of Ticket Texts\") \n",
    "plt.xlabel(\"Component 1\") \n",
    "plt.ylabel(\"Component 2\") \n",
    "plt.grid(True) \n",
    "plt.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef553cec",
   "metadata": {},
   "source": [
    "### Additional Visualizations & Metrics  \n",
    "Includes silhouette scores, word clouds, and intrinsic clustering quality metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_silhouette(X_dense, agglomerative_clusters, \"Silhouette - Agglomerative (Embeddings)\")\n",
    "plot_wordclouds(df[\"combined_text\"], agglomerative_clusters)\n",
    "evaluate_intrinsic_metrics(X_dense, agglomerative_clusters, \"Agglomerative (Embeddings)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
